{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.g2.com/categories/data-science-and-machine-learning-platforms\"\n",
    "response = requests.get(URL)\n",
    "print(response.status_code)\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "proxy_auth= \"\"\n",
    "\n",
    "# the list of proxy to rotate on \n",
    "# PROXIES = [\n",
    "#     f\"http://{proxy_auth}\",\n",
    "#     f\"https://{proxy_auth}\"\n",
    "# ]\n",
    "\n",
    "# # randomly select a proxy\n",
    "# proxy = random.choice(PROXIES)\n",
    "\n",
    "# set selenium-wire options to use the proxy\n",
    "seleniumwire_options = {\n",
    "    \"proxy\": {\n",
    "        \"http\": f\"http://{proxy_auth}\",\n",
    "        \"https\": f\"https://{proxy_auth}\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# set Chrome options to run in headless mode\n",
    "# options = Options()\n",
    "# options.add_argument(\"--headless=new\")\n",
    "\n",
    "# initialize the Chrome driver with service, selenium-wire options, and chrome options\n",
    "driver = webdriver.Chrome(\n",
    "    seleniumwire_options=seleniumwire_options\n",
    ")\n",
    "\n",
    "URL = \"https://www.g2.com/products/databricks-data-intelligence-platform/reviews\"\n",
    "\n",
    "driver.get(url=URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"product-head__title\"]\"}\n  (Session info: chrome=131.0.6778.86); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x000000010304fac4 cxxbridge1$str$ptr + 3651580\n1   chromedriver                        0x0000000103048314 cxxbridge1$str$ptr + 3620940\n2   chromedriver                        0x0000000102ab04b4 cxxbridge1$string$len + 89224\n3   chromedriver                        0x0000000102af4898 cxxbridge1$string$len + 368748\n4   chromedriver                        0x0000000102b2e0fc cxxbridge1$string$len + 604368\n5   chromedriver                        0x0000000102ae90b0 cxxbridge1$string$len + 321668\n6   chromedriver                        0x0000000102ae9d00 cxxbridge1$string$len + 324820\n7   chromedriver                        0x000000010301ae08 cxxbridge1$str$ptr + 3435328\n8   chromedriver                        0x000000010301e120 cxxbridge1$str$ptr + 3448408\n9   chromedriver                        0x000000010300217c cxxbridge1$str$ptr + 3333812\n10  chromedriver                        0x000000010301e9e0 cxxbridge1$str$ptr + 3450648\n11  chromedriver                        0x0000000102ff3988 cxxbridge1$str$ptr + 3274432\n12  chromedriver                        0x00000001030390f4 cxxbridge1$str$ptr + 3558956\n13  chromedriver                        0x0000000103039270 cxxbridge1$str$ptr + 3559336\n14  chromedriver                        0x0000000103047f88 cxxbridge1$str$ptr + 3620032\n15  libsystem_pthread.dylib             0x000000018d335f94 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000018d330d34 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m elem \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproduct-head__title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/cataloging_ML_AI_platforms/scraping/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:770\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchElementException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot locate relative element with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mby\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elements[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/cataloging_ML_AI_platforms/scraping/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:384\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Projects/cataloging_ML_AI_platforms/scraping/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[name=\"product-head__title\"]\"}\n  (Session info: chrome=131.0.6778.86); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x000000010304fac4 cxxbridge1$str$ptr + 3651580\n1   chromedriver                        0x0000000103048314 cxxbridge1$str$ptr + 3620940\n2   chromedriver                        0x0000000102ab04b4 cxxbridge1$string$len + 89224\n3   chromedriver                        0x0000000102af4898 cxxbridge1$string$len + 368748\n4   chromedriver                        0x0000000102b2e0fc cxxbridge1$string$len + 604368\n5   chromedriver                        0x0000000102ae90b0 cxxbridge1$string$len + 321668\n6   chromedriver                        0x0000000102ae9d00 cxxbridge1$string$len + 324820\n7   chromedriver                        0x000000010301ae08 cxxbridge1$str$ptr + 3435328\n8   chromedriver                        0x000000010301e120 cxxbridge1$str$ptr + 3448408\n9   chromedriver                        0x000000010300217c cxxbridge1$str$ptr + 3333812\n10  chromedriver                        0x000000010301e9e0 cxxbridge1$str$ptr + 3450648\n11  chromedriver                        0x0000000102ff3988 cxxbridge1$str$ptr + 3274432\n12  chromedriver                        0x00000001030390f4 cxxbridge1$str$ptr + 3558956\n13  chromedriver                        0x0000000103039270 cxxbridge1$str$ptr + 3559336\n14  chromedriver                        0x0000000103047f88 cxxbridge1$str$ptr + 3620032\n15  libsystem_pthread.dylib             0x000000018d335f94 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000018d330d34 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "elem = driver.find_element(By.NAME, \"product-head__title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'By' has no attribute 'CLASS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.g2.com/products/databricks-data-intelligence-platform/reviews\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url\u001b[38;5;241m=\u001b[39mURL)\n\u001b[0;32m---> 11\u001b[0m elem \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct-head__title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'By' has no attribute 'CLASS'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "# URL = \"https://www.g2.com/categories/data-science-and-machine-learning-platforms\"\n",
    "# Navigate to the URL\n",
    "URL = \"https://www.g2.com/products/databricks-data-intelligence-platform/reviews\"\n",
    "proxies = [\n",
    "    \n",
    "]\n",
    "driver.get(url=URL)\n",
    "\n",
    "elem = driver.find_element(By.CLASS, \"product-head__title\")\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# URL = \"https://www.g2.com/products/databricks-data-intelligence-platform/reviews\"\n",
    "URL = \"https://www.g2.com/categories/data-science-and-machine-learning-platforms?order=g2_score&page=17#product-list\"\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "proxy_auth= \"\"\n",
    "\n",
    "proxies = {\n",
    "        \"http\": f\"http://{proxy_auth}\",\n",
    "        \"https\": f\"https://{proxy_auth}\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': UserAgent().random,\n",
    "    'Accept-Language': 'en-GB,en;q=0.8',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.google.com'\n",
    "}\n",
    "time.sleep(2)\n",
    "r = session.get(URL, proxies=proxies, headers=headers)\n",
    "\n",
    "with open('something2.html', 'w') as f:\n",
    "    f.write(r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html_doc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m product_head_title \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct-head__title\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m sub_divs \u001b[38;5;241m=\u001b[39m \u001b[43mproduct_head_title\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Find all child divs\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(sub_divs)\n\u001b[1;32m     11\u001b[0m title \u001b[38;5;241m=\u001b[39m sub_divs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('something2.html', 'r') as f:\n",
    "    html_doc = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "product_head_title = soup.find('div', class_='product-head__title')\n",
    "# sub_divs = product_head_title.find_all('div')  # Find all child divs\n",
    "# print(sub_divs)\n",
    "title = sub_divs[0].text.strip()\n",
    "print(title)\n",
    "created_by = sub_divs[1].text.strip()\n",
    "print(created_by)\n",
    "\n",
    "about_company = soup.find('div', attrs={'data-max-height-expand-event-description': 'PDPs Overview Description'})\n",
    "about_company = about_company.text.strip()\n",
    "print(about_company)\n",
    "\n",
    "\n",
    "product_description_tags = soup.find_all('div', class_='hide-if-js')\n",
    "product_description_title = product_description[1].text.strip()\n",
    "# p_tag = product_description[1].find('p')\n",
    "product_description_and_information = product_description_tags[1]\n",
    "# prod_description = product_description_and_information.find_all('p')\n",
    "# print(product_description_and_information)\n",
    "# print(type(product_description_and_information))\n",
    "product_information = \"\"\n",
    "seller_information = \"\"\n",
    "seller = False # will improve on the naming\n",
    "for child in product_description_and_information.children: \n",
    "    if not seller and child.name == 'hr': \n",
    "        seller = True\n",
    "    if child.name:  \n",
    "        if not seller:\n",
    "            product_information += child.text.strip()\n",
    "        else:\n",
    "            seller_information += child.text.strip() # seller information can be formatted even more.\n",
    "\n",
    "print(product_information)\n",
    "print(\"are balle balle\")\n",
    "print(seller_information)\n",
    "\n",
    "\n",
    "# pricing information next page (another page)\n",
    "pricing_cost = soup.find_all('td', class_=\"editions__pricing editions__pricing--vertical\") # get all the information from their spans. \n",
    "pricing_description = soup.find_all('td', class_=\"editions__description editions__description--spaced\")\n",
    "\n",
    "\n",
    "\n",
    "# main function\n",
    "links = soup.find_all('a', class_='d-ib c-midnight-100 js-log-click')\n",
    "for link in links:\n",
    "    if link and 'href' in link.attrs:\n",
    "        href = link['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "tag = soup.find('a', attrs={'data-event-options': '{\"value\":\"next\",\"name\":\"Event::PaginationClicked\"}'})\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product DescriptionMaking big data simple\n",
      "are balle balle\n",
      "Seller DetailsSellerDatabricks Inc.\n",
      "Company Websitedatabricks.comYear Founded1999\n",
      "HQ LocationSan Francisco, CATwitter@databricks74,132 Twitter followersLinkedIn® Pagewww.linkedin.com9,669 employees on LinkedIn®DescriptionDatabricks is an AI cloud data platform that interacts with corporate information stored in the public cloud.CCOverview Provided by:Colette Chavalia\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('something.html', 'r') as f:\n",
    "    html_doc = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "# product_head_title = soup.find('div', class_='product-head__title')\n",
    "# sub_divs = product_head_title.find_all('div')  # Find all child divs\n",
    "# print(sub_divs)\n",
    "# title = sub_divs[0].text.strip()\n",
    "# print(title)\n",
    "# created_by = sub_divs[1].text.strip()\n",
    "# print(created_by)\n",
    "\n",
    "# about_company = soup.find('div', attrs={'data-max-height-expand-event-description': 'PDPs Overview Description'})\n",
    "# about_company = about_company.text.strip()\n",
    "# print(about_company)\n",
    "\n",
    "\n",
    "product_description_tags = soup.find_all('div', class_='hide-if-js')\n",
    "product_description_title = product_description[1].text.strip()\n",
    "# p_tag = product_description[1].find('p')\n",
    "product_description_and_information = product_description_tags[1]\n",
    "# prod_description = product_description_and_information.find_all('p')\n",
    "# print(product_description_and_information)\n",
    "# print(type(product_description_and_information))\n",
    "product_information = \"\"\n",
    "seller_information = \"\"\n",
    "seller = False # will improve on the naming\n",
    "for child in product_description_and_information.children: \n",
    "    if not seller and child.name == 'hr': \n",
    "        seller = True\n",
    "    if child.name:  \n",
    "        if not seller:\n",
    "            product_information += child.text.strip()\n",
    "        else:\n",
    "            seller_information += child.text.strip() # seller information can be formatted even more.\n",
    "\n",
    "print(product_information)\n",
    "print(\"are balle balle\")\n",
    "print(seller_information)\n",
    "\n",
    "\n",
    "# pricing information next page (another page)\n",
    "pricing_cost = soup.find_all('td', class_=\"editions__pricing editions__pricing--vertical\") # get all the information from their spans. \n",
    "pricing_description = soup.find_all('td', class_=\"editions__description editions__description--spaced\")\n",
    "\n",
    "\n",
    "\n",
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/jt/7yhj4ggd2qd1sl17h7_vynhh0000gq/T/tmp7e52aib_.html\n",
      "something\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "temp_file = tempfile.NamedTemporaryFile()\n",
    "print(temp_file.name + \".html\")\n",
    "with open(temp_file.name, 'w') as f:\n",
    "    f.write(\"something\")\n",
    "with open(temp_file.name, 'r') as f:\n",
    "    text = f.read()\n",
    "print(text)\n",
    "temp_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrawling_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_html_website_content_to_file\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'app'"
     ]
    }
   ],
   "source": [
    "from app.services.crawling_service import write_html_website_content_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"pagination__named-link js-log-click pjax\" data-event-options='{\"value\":\"next\",\"name\":\"Event::PaginationClicked\"}' data-turbo=\"false\" href=\"https://www.g2.com/categories/data-science-and-machine-learning-platforms?order=g2_score&amp;page=2#product-list\" rel=\"nofollow\">Next ›</a>\n",
      "https://www.g2.com/categories/data-science-and-machine-learning-platforms?order=g2_score&page=2#product-list\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "with open(\"main_page.html\", 'r') as f:\n",
    "        html_doc = f.read()\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "links = soup.find_all('a', class_='d-ib c-midnight-100 js-log-click')\n",
    "link = links[0]\n",
    "links_list: List[Dict] = []\n",
    "counter = 0\n",
    "for link in links:\n",
    "    if link and 'href' in link.attrs:\n",
    "        counter = counter + 1\n",
    "        href = link['href']\n",
    "        name = link.text.strip()\n",
    "        # print(href, name)\n",
    "        links_list.append({\"name\": name, \"link\": href})\n",
    "        if(counter == 5): break\n",
    "\n",
    "next_tag = soup.find('a', attrs={'data-event-options': '{\"value\":\"next\",\"name\":\"Event::PaginationClicked\"}'})\n",
    "print(next_tag)\n",
    "print(next_tag['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
